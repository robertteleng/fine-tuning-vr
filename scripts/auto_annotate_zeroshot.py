#!/usr/bin/env python3
"""
Auto-anotaciÃ³n Zero-Shot usando YOLO-World.

Este script usa YOLO-World para detectar objetos basÃ¡ndose en descripciones
de texto (prompts) en lugar de necesitar ejemplos etiquetados.

CÃ“MO FUNCIONA:
1. Cargas YOLO-World (modelo pre-entrenado con CLIP)
2. Le dices QUÃ‰ buscar con texto: "yellow checkered box"
3. YOLO-World detecta esos objetos en tus imÃ¡genes
4. Genera archivos .txt en formato YOLO para entrenar

Ejemplo de uso:
    python scripts/auto_annotate_zeroshot.py \
        --source data/video_frames/ \
        --prompts "yellow checkered pillar" \
        --output data/dataset_zeroshot/ \
        --conf 0.3
"""

import argparse
from pathlib import Path
from datetime import datetime
import shutil
import yaml

# ============================================================================
# PASO 1: Importar YOLO-World desde Ultralytics
# ============================================================================
# Ultralytics incluye YOLO-World, que combina YOLO con CLIP para
# entender descripciones de texto y buscar objetos que coincidan.
from ultralytics import YOLO


def parse_args():
    """Parsear argumentos de lÃ­nea de comandos."""
    parser = argparse.ArgumentParser(
        description='Auto-anotaciÃ³n Zero-Shot con YOLO-World',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos:
  # Detectar un tipo de objeto:
  python scripts/auto_annotate_zeroshot.py \\
      --source data/video_frames/ \\
      --prompts "yellow checkered pillar" \\
      --output data/dataset_zeroshot/

  # Detectar mÃºltiples objetos:
  python scripts/auto_annotate_zeroshot.py \\
      --source data/video_frames/ \\
      --prompts "yellow pillar" "blue box" "orange cone" \\
      --output data/dataset_zeroshot/ \\
      --conf 0.25

  # Usar modelo mÃ¡s grande para mejor precisiÃ³n:
  python scripts/auto_annotate_zeroshot.py \\
      --source data/video_frames/ \\
      --prompts "yellow checkered pillar" \\
      --model yolov8l-worldv2.pt \\
      --conf 0.2
        """
    )

    # Argumentos requeridos
    parser.add_argument(
        '--source', type=str, required=True,
        help='Carpeta con imÃ¡genes a anotar (jpg, png)'
    )
    parser.add_argument(
        '--prompts', type=str, nargs='+', required=True,
        help='DescripciÃ³n(es) de los objetos a detectar. Cada prompt es una clase.'
    )
    parser.add_argument(
        '--output', type=str, required=True,
        help='Carpeta de salida para el dataset'
    )

    # Argumentos opcionales
    parser.add_argument(
        '--model', type=str, default='yolov8x-worldv2.pt',
        help='Modelo YOLO-World a usar (default: yolov8x-worldv2.pt)'
    )
    parser.add_argument(
        '--conf', type=float, default=0.3,
        help='Umbral de confianza mÃ­nimo (0-1). Menor=mÃ¡s detecciones. Default: 0.3'
    )
    parser.add_argument(
        '--iou', type=float, default=0.5,
        help='Umbral IoU para NMS. Default: 0.5'
    )
    parser.add_argument(
        '--imgsz', type=int, default=640,
        help='TamaÃ±o de imagen para inferencia. Default: 640'
    )
    parser.add_argument(
        '--device', type=str, default='0',
        help='Device: "0" para GPU, "cpu" para CPU. Default: 0'
    )
    parser.add_argument(
        '--class-names', type=str, nargs='+', default=None,
        help='Nombres de clase para el dataset (si no se especifica, usa los prompts)'
    )
    parser.add_argument(
        '--val-split', type=float, default=0.2,
        help='FracciÃ³n para validaciÃ³n (0-1). Default: 0.2'
    )
    parser.add_argument(
        '--copy-images', action='store_true',
        help='Copiar imÃ¡genes al dataset (si no, crea symlinks)'
    )
    parser.add_argument(
        '--visualize', type=int, default=0,
        help='Guardar N imÃ¡genes con detecciones visualizadas. Default: 0'
    )

    return parser.parse_args()


def setup_output_dirs(output_path: Path) -> dict:
    """
    Crear estructura de carpetas para dataset YOLO.

    Estructura creada:
        output/
        â”œâ”€â”€ images/
        â”‚   â”œâ”€â”€ train/
        â”‚   â””â”€â”€ val/
        â”œâ”€â”€ labels/
        â”‚   â”œâ”€â”€ train/
        â”‚   â””â”€â”€ val/
        â””â”€â”€ dataset.yaml
    """
    dirs = {
        'images_train': output_path / 'images' / 'train',
        'images_val': output_path / 'images' / 'val',
        'labels_train': output_path / 'labels' / 'train',
        'labels_val': output_path / 'labels' / 'val',
        'visualize': output_path / 'visualizations',
    }

    for dir_path in dirs.values():
        dir_path.mkdir(parents=True, exist_ok=True)

    return dirs


def load_yolo_world(model_name: str, prompts: list, device: str) -> YOLO:
    """
    Cargar YOLO-World y configurar las clases a detectar.

    EXPLICACIÃ“N:
    - YOLO-World usa CLIP internamente para entender texto
    - Cuando hacemos model.set_classes(prompts), le decimos quÃ© buscar
    - El modelo convierte cada prompt a un "embedding" (vector numÃ©rico)
    - Luego compara ese vector con lo que ve en la imagen
    """
    print(f"\n{'='*60}")
    print("PASO 1: Cargando modelo YOLO-World")
    print(f"{'='*60}")
    print(f"  Modelo: {model_name}")
    print(f"  Device: {device}")

    # Cargar el modelo
    model = YOLO(model_name)

    # Â¡CLAVE! Configurar quÃ© objetos queremos detectar
    # Esto es lo que hace "zero-shot": no necesitamos entrenar,
    # solo decirle quÃ© buscar con texto
    print(f"\n  Configurando clases a detectar:")
    for i, prompt in enumerate(prompts):
        print(f"    Clase {i}: '{prompt}'")

    model.set_classes(prompts)

    print(f"\n  âœ“ Modelo cargado y configurado")
    return model


def find_images(source_path: Path) -> list:
    """Encontrar todas las imÃ¡genes en el directorio."""
    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.webp']
    images = []
    for ext in extensions:
        images.extend(source_path.glob(ext))
        images.extend(source_path.glob(ext.upper()))
    return sorted(images)


def detection_to_yolo_format(box, img_width: int, img_height: int) -> str:
    """
    Convertir una detecciÃ³n al formato YOLO.

    Formato YOLO: class_id x_center y_center width height
    - Todos los valores estÃ¡n normalizados (0-1)
    - x_center, y_center: centro del bounding box
    - width, height: dimensiones del box
    """
    # Extraer datos de la detecciÃ³n
    class_id = int(box.cls[0])
    x1, y1, x2, y2 = box.xyxy[0].tolist()

    # Calcular centro y dimensiones normalizadas
    x_center = ((x1 + x2) / 2) / img_width
    y_center = ((y1 + y2) / 2) / img_height
    width = (x2 - x1) / img_width
    height = (y2 - y1) / img_height

    return f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}"


def process_images(
    model: YOLO,
    images: list,
    dirs: dict,
    args,
) -> dict:
    """
    Procesar todas las imÃ¡genes y generar anotaciones.

    Para cada imagen:
    1. YOLO-World busca objetos que coincidan con los prompts
    2. Filtra detecciones por confianza
    3. Guarda el archivo .txt con las anotaciones
    4. Copia/enlaza la imagen al dataset
    """
    from tqdm import tqdm
    import random

    print(f"\n{'='*60}")
    print("PASO 2: Procesando imÃ¡genes")
    print(f"{'='*60}")
    print(f"  Total imÃ¡genes: {len(images)}")
    print(f"  Umbral confianza: {args.conf}")
    print(f"  TamaÃ±o inferencia: {args.imgsz}")

    # EstadÃ­sticas
    stats = {
        'total_images': len(images),
        'images_with_detections': 0,
        'total_detections': 0,
        'detections_per_class': {},
        'train_images': 0,
        'val_images': 0,
    }

    # Mezclar imÃ¡genes para split aleatorio
    images_shuffled = images.copy()
    random.seed(42)  # Para reproducibilidad
    random.shuffle(images_shuffled)

    # Calcular Ã­ndice de corte para train/val
    val_count = int(len(images_shuffled) * args.val_split)
    val_images = set(images_shuffled[:val_count])

    # Contador para visualizaciones
    viz_count = 0

    # Procesar cada imagen
    for img_path in tqdm(images, desc="Anotando"):
        # Determinar si es train o val
        is_val = img_path in val_images
        split = 'val' if is_val else 'train'

        # ============================================================
        # AQUÃ ESTÃ LA MAGIA: YOLO-World hace la detecciÃ³n
        # ============================================================
        # model.predict() busca objetos que coincidan con los prompts
        # que configuramos con set_classes()
        results = model.predict(
            source=str(img_path),
            conf=args.conf,
            iou=args.iou,
            imgsz=args.imgsz,
            device=args.device,
            verbose=False,
        )

        # Obtener el resultado (solo hay uno porque procesamos una imagen)
        result = results[0]
        boxes = result.boxes

        # Obtener dimensiones de la imagen
        img_height, img_width = result.orig_shape

        # Convertir detecciones a formato YOLO
        yolo_lines = []
        for box in boxes:
            line = detection_to_yolo_format(box, img_width, img_height)
            yolo_lines.append(line)

            # Actualizar estadÃ­sticas
            class_id = int(box.cls[0])
            class_name = model.names[class_id]
            stats['detections_per_class'][class_name] = \
                stats['detections_per_class'].get(class_name, 0) + 1

        # Actualizar estadÃ­sticas
        if len(yolo_lines) > 0:
            stats['images_with_detections'] += 1
        stats['total_detections'] += len(yolo_lines)

        if is_val:
            stats['val_images'] += 1
        else:
            stats['train_images'] += 1

        # Guardar archivo de etiquetas (.txt)
        label_dir = dirs['labels_val'] if is_val else dirs['labels_train']
        label_path = label_dir / f"{img_path.stem}.txt"
        with open(label_path, 'w') as f:
            f.write('\n'.join(yolo_lines))

        # Copiar o enlazar imagen
        img_dir = dirs['images_val'] if is_val else dirs['images_train']
        img_dest = img_dir / img_path.name

        if args.copy_images:
            shutil.copy2(img_path, img_dest)
        else:
            # Crear symlink (mÃ¡s rÃ¡pido y ahorra espacio)
            if not img_dest.exists():
                img_dest.symlink_to(img_path.absolute())

        # Guardar visualizaciÃ³n si se solicitÃ³
        if args.visualize > 0 and viz_count < args.visualize and len(yolo_lines) > 0:
            viz_path = dirs['visualize'] / f"viz_{img_path.stem}.jpg"
            result.save(str(viz_path))
            viz_count += 1

    return stats


def create_dataset_yaml(output_path: Path, class_names: list) -> Path:
    """
    Crear archivo dataset.yaml para entrenamiento YOLO.

    Este archivo le dice a YOLO:
    - DÃ³nde estÃ¡n las imÃ¡genes
    - CuÃ¡ntas clases hay
    - CÃ³mo se llama cada clase
    """
    yaml_content = {
        'path': str(output_path.absolute()),
        'train': 'images/train',
        'val': 'images/val',
        'names': {i: name for i, name in enumerate(class_names)},
    }

    yaml_path = output_path / 'dataset.yaml'
    with open(yaml_path, 'w') as f:
        yaml.dump(yaml_content, f, default_flow_style=False, sort_keys=False)

    return yaml_path


def print_summary(stats: dict, yaml_path: Path, class_names: list):
    """Imprimir resumen de la anotaciÃ³n."""
    print(f"\n{'='*60}")
    print("RESUMEN")
    print(f"{'='*60}")

    print(f"\nğŸ“Š EstadÃ­sticas:")
    print(f"  Total imÃ¡genes procesadas: {stats['total_images']}")
    print(f"  ImÃ¡genes con detecciones:  {stats['images_with_detections']}")
    print(f"  ImÃ¡genes sin detecciones:  {stats['total_images'] - stats['images_with_detections']}")
    print(f"  Total detecciones:         {stats['total_detections']}")

    if stats['total_images'] > 0:
        avg = stats['total_detections'] / stats['total_images']
        coverage = stats['images_with_detections'] / stats['total_images'] * 100
        print(f"  Promedio por imagen:       {avg:.2f}")
        print(f"  Cobertura:                 {coverage:.1f}%")

    print(f"\nğŸ“ Split del dataset:")
    print(f"  Train: {stats['train_images']} imÃ¡genes")
    print(f"  Val:   {stats['val_images']} imÃ¡genes")

    print(f"\nğŸ·ï¸ Detecciones por clase:")
    for class_name, count in stats['detections_per_class'].items():
        print(f"  {class_name}: {count}")

    print(f"\nğŸ“„ Dataset YAML: {yaml_path}")

    print(f"\n{'='*60}")
    print("SIGUIENTE PASO: Entrenar tu modelo")
    print(f"{'='*60}")
    print(f"""
Para entrenar con estas anotaciones:

    python scripts/train.py \\
        --data {yaml_path} \\
        --model yolo12n.pt \\
        --epochs 100 \\
        --batch 16

O directamente con Ultralytics:

    from ultralytics import YOLO
    model = YOLO('yolo12n.pt')
    model.train(data='{yaml_path}', epochs=100, batch=16)
""")


def main():
    """FunciÃ³n principal."""
    args = parse_args()

    # Convertir paths
    source_path = Path(args.source)
    output_path = Path(args.output)

    # Validar que existe el directorio fuente
    if not source_path.exists():
        raise FileNotFoundError(f"No existe el directorio: {source_path}")

    print(f"\n{'#'*60}")
    print("#  AUTO-ANOTACIÃ“N ZERO-SHOT CON YOLO-WORLD")
    print(f"#  {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'#'*60}")
    print(f"\nğŸ“‚ Fuente:  {source_path}")
    print(f"ğŸ“‚ Salida:  {output_path}")
    print(f"ğŸ“ Prompts: {args.prompts}")

    # Crear estructura de carpetas
    dirs = setup_output_dirs(output_path)

    # Encontrar imÃ¡genes
    images = find_images(source_path)
    if len(images) == 0:
        raise ValueError(f"No se encontraron imÃ¡genes en {source_path}")
    print(f"\nğŸ–¼ï¸ ImÃ¡genes encontradas: {len(images)}")

    # Cargar modelo
    model = load_yolo_world(args.model, args.prompts, args.device)

    # Procesar imÃ¡genes
    stats = process_images(model, images, dirs, args)

    # Crear dataset.yaml
    class_names = args.class_names if args.class_names else args.prompts
    # Limpiar nombres de clase (sin espacios, lowercase)
    class_names = [name.replace(' ', '_').lower() for name in class_names]
    yaml_path = create_dataset_yaml(output_path, class_names)

    # Mostrar resumen
    print_summary(stats, yaml_path, class_names)


if __name__ == '__main__':
    main()
