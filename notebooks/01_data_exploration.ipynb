{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploraci√≥n del Dataset - Cajas VR\n",
    "\n",
    "Este notebook permite explorar y validar el dataset antes del entrenamiento.\n",
    "\n",
    "## Objetivos\n",
    "1. Verificar la estructura del dataset\n",
    "2. Visualizar im√°genes con sus anotaciones\n",
    "3. Analizar la distribuci√≥n de clases\n",
    "4. Detectar posibles problemas en las anotaciones\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Importaciones necesarias\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Procesamiento de im√°genes\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Configurar el directorio del proyecto\n",
    "PROJECT_ROOT = Path().absolute().parent\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "print(f\"Directorio del proyecto: {PROJECT_ROOT}\")\n",
    "print(f\"Directorio de datos: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuraci√≥n del Dataset\n",
    "\n",
    "Define las clases y verifica la estructura de carpetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Configuraci√≥n de clases\n",
    "# IMPORTANTE: Ajusta estos nombres seg√∫n tu dataset de Roboflow\n",
    "# =============================================================================\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: 'vr_box_type_a',    # Clase 0: Ajusta el nombre\n",
    "    1: 'vr_box_type_b',    # Clase 1: Ajusta el nombre\n",
    "}\n",
    "\n",
    "# Colores para visualizaci√≥n (RGB)\n",
    "CLASS_COLORS = {\n",
    "    0: '#FF6B6B',  # Rojo coral\n",
    "    1: '#4ECDC4',  # Turquesa\n",
    "}\n",
    "\n",
    "print(\"Clases configuradas:\")\n",
    "for idx, name in CLASS_NAMES.items():\n",
    "    print(f\"  {idx}: {name} ({CLASS_COLORS[idx]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Verificar estructura del dataset\n",
    "# =============================================================================\n",
    "\n",
    "def check_dataset_structure():\n",
    "    \"\"\"Verifica que la estructura del dataset sea correcta.\"\"\"\n",
    "    \n",
    "    splits = ['train', 'valid', 'test']\n",
    "    structure_ok = True\n",
    "    \n",
    "    print(\"Verificando estructura del dataset...\\n\")\n",
    "    \n",
    "    for split in splits:\n",
    "        split_dir = DATA_DIR / split\n",
    "        images_dir = split_dir / 'images'\n",
    "        labels_dir = split_dir / 'labels'\n",
    "        \n",
    "        print(f\"üìÅ {split}/\")\n",
    "        \n",
    "        # Verificar carpeta de im√°genes\n",
    "        if images_dir.exists():\n",
    "            num_images = len(list(images_dir.glob('*.[jJpP][pPnN][gG]')))\n",
    "            print(f\"   ‚îú‚îÄ‚îÄ images/: {num_images} im√°genes ‚úÖ\")\n",
    "        else:\n",
    "            print(f\"   ‚îú‚îÄ‚îÄ images/: NO ENCONTRADA ‚ùå\")\n",
    "            structure_ok = False\n",
    "        \n",
    "        # Verificar carpeta de labels\n",
    "        if labels_dir.exists():\n",
    "            num_labels = len(list(labels_dir.glob('*.txt')))\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ labels/: {num_labels} archivos ‚úÖ\")\n",
    "        else:\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ labels/: NO ENCONTRADA ‚ùå\")\n",
    "            structure_ok = False\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    if structure_ok:\n",
    "        print(\"‚úÖ Estructura del dataset correcta\")\n",
    "    else:\n",
    "        print(\"‚ùå Hay problemas con la estructura del dataset\")\n",
    "        print(\"   Aseg√∫rate de exportar el dataset de Roboflow en formato YOLOv8\")\n",
    "    \n",
    "    return structure_ok\n",
    "\n",
    "dataset_ok = check_dataset_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lisis de Distribuci√≥n de Clases\n",
    "\n",
    "Es importante verificar que las clases est√©n balanceadas para evitar sesgo en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Funciones de utilidad para parsear anotaciones YOLO\n",
    "# =============================================================================\n",
    "\n",
    "def parse_yolo_label(label_path):\n",
    "    \"\"\"\n",
    "    Parsea un archivo de label YOLO.\n",
    "    \n",
    "    Formato YOLO: class_id x_center y_center width height (normalizados 0-1)\n",
    "    \n",
    "    Args:\n",
    "        label_path: Ruta al archivo .txt\n",
    "        \n",
    "    Returns:\n",
    "        Lista de diccionarios con las anotaciones\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    \n",
    "    if not Path(label_path).exists():\n",
    "        return annotations\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                annotations.append({\n",
    "                    'class_id': int(parts[0]),\n",
    "                    'x_center': float(parts[1]),\n",
    "                    'y_center': float(parts[2]),\n",
    "                    'width': float(parts[3]),\n",
    "                    'height': float(parts[4]),\n",
    "                })\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "\n",
    "def collect_all_annotations(split='train'):\n",
    "    \"\"\"\n",
    "    Recolecta todas las anotaciones de un split.\n",
    "    \n",
    "    Args:\n",
    "        split: 'train', 'valid', o 'test'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame con todas las anotaciones\n",
    "    \"\"\"\n",
    "    labels_dir = DATA_DIR / split / 'labels'\n",
    "    images_dir = DATA_DIR / split / 'images'\n",
    "    \n",
    "    all_annotations = []\n",
    "    \n",
    "    if not labels_dir.exists():\n",
    "        print(f\"‚ö†Ô∏è Directorio no encontrado: {labels_dir}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    for label_file in labels_dir.glob('*.txt'):\n",
    "        annotations = parse_yolo_label(label_file)\n",
    "        \n",
    "        # Buscar imagen correspondiente\n",
    "        img_name = label_file.stem\n",
    "        img_path = None\n",
    "        for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n",
    "            potential_path = images_dir / f\"{img_name}{ext}\"\n",
    "            if potential_path.exists():\n",
    "                img_path = potential_path\n",
    "                break\n",
    "        \n",
    "        for ann in annotations:\n",
    "            ann['split'] = split\n",
    "            ann['label_file'] = label_file.name\n",
    "            ann['image_file'] = img_path.name if img_path else None\n",
    "            all_annotations.append(ann)\n",
    "    \n",
    "    return pd.DataFrame(all_annotations)\n",
    "\n",
    "print(\"Funciones de utilidad cargadas ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Recolectar y analizar anotaciones de todos los splits\n",
    "# =============================================================================\n",
    "\n",
    "# Recolectar anotaciones\n",
    "df_train = collect_all_annotations('train')\n",
    "df_valid = collect_all_annotations('valid')\n",
    "df_test = collect_all_annotations('test')\n",
    "\n",
    "# Combinar todos los datos\n",
    "df_all = pd.concat([df_train, df_valid, df_test], ignore_index=True)\n",
    "\n",
    "if len(df_all) > 0:\n",
    "    print(f\"\\nüìä Resumen del Dataset:\")\n",
    "    print(f\"   Total de anotaciones: {len(df_all)}\")\n",
    "    print(f\"   - Train: {len(df_train)}\")\n",
    "    print(f\"   - Valid: {len(df_valid)}\")\n",
    "    print(f\"   - Test: {len(df_test)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontraron anotaciones. Aseg√∫rate de que el dataset est√© en data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Visualizar distribuci√≥n de clases\n",
    "# =============================================================================\n",
    "\n",
    "if len(df_all) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Gr√°fico 1: Distribuci√≥n total de clases\n",
    "    class_counts = df_all['class_id'].value_counts().sort_index()\n",
    "    colors = [CLASS_COLORS.get(i, '#666666') for i in class_counts.index]\n",
    "    \n",
    "    ax1 = axes[0]\n",
    "    bars = ax1.bar(class_counts.index, class_counts.values, color=colors, edgecolor='black')\n",
    "    ax1.set_xlabel('Clase')\n",
    "    ax1.set_ylabel('N√∫mero de instancias')\n",
    "    ax1.set_title('Distribuci√≥n de Clases (Total)')\n",
    "    ax1.set_xticks(list(CLASS_NAMES.keys()))\n",
    "    ax1.set_xticklabels([CLASS_NAMES.get(i, f'Clase {i}') for i in class_counts.index])\n",
    "    \n",
    "    # A√±adir valores sobre las barras\n",
    "    for bar, count in zip(bars, class_counts.values):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                 str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Gr√°fico 2: Distribuci√≥n por split\n",
    "    ax2 = axes[1]\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    x = np.arange(len(CLASS_NAMES))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, split in enumerate(splits):\n",
    "        df_split = df_all[df_all['split'] == split]\n",
    "        counts = [len(df_split[df_split['class_id'] == c]) for c in CLASS_NAMES.keys()]\n",
    "        ax2.bar(x + i*width, counts, width, label=split.capitalize())\n",
    "    \n",
    "    ax2.set_xlabel('Clase')\n",
    "    ax2.set_ylabel('N√∫mero de instancias')\n",
    "    ax2.set_title('Distribuci√≥n de Clases por Split')\n",
    "    ax2.set_xticks(x + width)\n",
    "    ax2.set_xticklabels([CLASS_NAMES.get(i, f'Clase {i}') for i in CLASS_NAMES.keys()])\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calcular balance de clases\n",
    "    print(\"\\nüìà Balance de clases:\")\n",
    "    total = len(df_all)\n",
    "    for class_id in CLASS_NAMES.keys():\n",
    "        count = len(df_all[df_all['class_id'] == class_id])\n",
    "        percentage = (count / total) * 100\n",
    "        print(f\"   {CLASS_NAMES[class_id]}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Advertencia si hay desbalance\n",
    "    percentages = [(len(df_all[df_all['class_id'] == c]) / total) * 100 for c in CLASS_NAMES.keys()]\n",
    "    if max(percentages) / min(percentages) > 3:\n",
    "        print(\"\\n‚ö†Ô∏è ADVERTENCIA: Las clases est√°n muy desbalanceadas\")\n",
    "        print(\"   Considera agregar m√°s datos de la clase minoritaria\")\n",
    "else:\n",
    "    print(\"No hay datos para visualizar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. An√°lisis de Tama√±os de Bounding Boxes\n",
    "\n",
    "Entender el tama√±o de los objetos ayuda a configurar mejor el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Analizar tama√±os de bounding boxes\n",
    "# =============================================================================\n",
    "\n",
    "if len(df_all) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Gr√°fico 1: Distribuci√≥n de anchos\n",
    "    ax1 = axes[0]\n",
    "    for class_id in CLASS_NAMES.keys():\n",
    "        df_class = df_all[df_all['class_id'] == class_id]\n",
    "        ax1.hist(df_class['width'], bins=20, alpha=0.6, \n",
    "                 label=CLASS_NAMES[class_id], color=CLASS_COLORS[class_id])\n",
    "    ax1.set_xlabel('Ancho (normalizado)')\n",
    "    ax1.set_ylabel('Frecuencia')\n",
    "    ax1.set_title('Distribuci√≥n de Anchos')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Gr√°fico 2: Distribuci√≥n de altos\n",
    "    ax2 = axes[1]\n",
    "    for class_id in CLASS_NAMES.keys():\n",
    "        df_class = df_all[df_all['class_id'] == class_id]\n",
    "        ax2.hist(df_class['height'], bins=20, alpha=0.6, \n",
    "                 label=CLASS_NAMES[class_id], color=CLASS_COLORS[class_id])\n",
    "    ax2.set_xlabel('Alto (normalizado)')\n",
    "    ax2.set_ylabel('Frecuencia')\n",
    "    ax2.set_title('Distribuci√≥n de Altos')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Gr√°fico 3: Scatter de ancho vs alto\n",
    "    ax3 = axes[2]\n",
    "    for class_id in CLASS_NAMES.keys():\n",
    "        df_class = df_all[df_all['class_id'] == class_id]\n",
    "        ax3.scatter(df_class['width'], df_class['height'], alpha=0.5,\n",
    "                   label=CLASS_NAMES[class_id], color=CLASS_COLORS[class_id])\n",
    "    ax3.set_xlabel('Ancho (normalizado)')\n",
    "    ax3.set_ylabel('Alto (normalizado)')\n",
    "    ax3.set_title('Ancho vs Alto de Bounding Boxes')\n",
    "    ax3.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Estad√≠sticas\n",
    "    print(\"\\nüìê Estad√≠sticas de tama√±o de bounding boxes:\")\n",
    "    for class_id in CLASS_NAMES.keys():\n",
    "        df_class = df_all[df_all['class_id'] == class_id]\n",
    "        if len(df_class) > 0:\n",
    "            print(f\"\\n   {CLASS_NAMES[class_id]}:\")\n",
    "            print(f\"      Ancho: {df_class['width'].mean():.3f} ¬± {df_class['width'].std():.3f}\")\n",
    "            print(f\"      Alto:  {df_class['height'].mean():.3f} ¬± {df_class['height'].std():.3f}\")\n",
    "            area = df_class['width'] * df_class['height']\n",
    "            print(f\"      √Årea:  {area.mean():.4f} ¬± {area.std():.4f}\")\n",
    "else:\n",
    "    print(\"No hay datos para analizar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizaci√≥n de Im√°genes con Anotaciones\n",
    "\n",
    "Verificar visualmente que las anotaciones son correctas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Funci√≥n para visualizar imagen con anotaciones\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_image_with_annotations(image_path, label_path, figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Muestra una imagen con sus bounding boxes anotados.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Ruta a la imagen\n",
    "        label_path: Ruta al archivo de label\n",
    "        figsize: Tama√±o de la figura\n",
    "    \"\"\"\n",
    "    # Cargar imagen\n",
    "    img = Image.open(image_path)\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Parsear anotaciones\n",
    "    annotations = parse_yolo_label(label_path)\n",
    "    \n",
    "    # Crear figura\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Dibujar cada bounding box\n",
    "    for ann in annotations:\n",
    "        # Convertir de formato YOLO (centro, tama√±o normalizado) a p√≠xeles\n",
    "        x_center = ann['x_center'] * img_width\n",
    "        y_center = ann['y_center'] * img_height\n",
    "        width = ann['width'] * img_width\n",
    "        height = ann['height'] * img_height\n",
    "        \n",
    "        # Calcular esquina superior izquierda\n",
    "        x1 = x_center - width / 2\n",
    "        y1 = y_center - height / 2\n",
    "        \n",
    "        # Obtener color y nombre de clase\n",
    "        class_id = ann['class_id']\n",
    "        color = CLASS_COLORS.get(class_id, '#666666')\n",
    "        class_name = CLASS_NAMES.get(class_id, f'Clase {class_id}')\n",
    "        \n",
    "        # Dibujar rect√°ngulo\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height,\n",
    "            linewidth=2, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # A√±adir etiqueta\n",
    "        ax.text(x1, y1 - 5, class_name, color='white', fontsize=10,\n",
    "               fontweight='bold', bbox=dict(boxstyle='round', facecolor=color, alpha=0.8))\n",
    "    \n",
    "    ax.set_title(f\"{Path(image_path).name} - {len(annotations)} anotaciones\")\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Funci√≥n de visualizaci√≥n cargada ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Visualizar algunas im√°genes de ejemplo\n",
    "# =============================================================================\n",
    "\n",
    "def show_random_samples(split='train', n_samples=4):\n",
    "    \"\"\"\n",
    "    Muestra n_samples im√°genes aleatorias del split especificado.\n",
    "    \"\"\"\n",
    "    images_dir = DATA_DIR / split / 'images'\n",
    "    labels_dir = DATA_DIR / split / 'labels'\n",
    "    \n",
    "    if not images_dir.exists():\n",
    "        print(f\"‚ö†Ô∏è Directorio no encontrado: {images_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Obtener lista de im√°genes\n",
    "    image_files = list(images_dir.glob('*.[jJpP][pPnN][gG]'))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"‚ö†Ô∏è No se encontraron im√°genes en {images_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Seleccionar muestras aleatorias\n",
    "    n_samples = min(n_samples, len(image_files))\n",
    "    selected = np.random.choice(image_files, n_samples, replace=False)\n",
    "    \n",
    "    print(f\"\\nüñºÔ∏è Mostrando {n_samples} im√°genes de {split}:\\n\")\n",
    "    \n",
    "    for img_path in selected:\n",
    "        label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "        visualize_image_with_annotations(img_path, label_path)\n",
    "\n",
    "# Mostrar ejemplos del set de entrenamiento\n",
    "show_random_samples('train', n_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verificaci√≥n de Calidad de Datos\n",
    "\n",
    "Detectar posibles problemas en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Verificar calidad de datos\n",
    "# =============================================================================\n",
    "\n",
    "def check_data_quality(split='train'):\n",
    "    \"\"\"\n",
    "    Verifica la calidad de los datos de un split.\n",
    "    \n",
    "    Busca:\n",
    "    - Im√°genes sin labels\n",
    "    - Labels sin im√°genes\n",
    "    - Bounding boxes fuera de rango\n",
    "    - Clases inv√°lidas\n",
    "    \"\"\"\n",
    "    images_dir = DATA_DIR / split / 'images'\n",
    "    labels_dir = DATA_DIR / split / 'labels'\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    if not images_dir.exists() or not labels_dir.exists():\n",
    "        print(f\"‚ö†Ô∏è Directorios no encontrados para {split}\")\n",
    "        return\n",
    "    \n",
    "    # Obtener sets de archivos\n",
    "    image_stems = {f.stem for f in images_dir.glob('*.[jJpP][pPnN][gG]')}\n",
    "    label_stems = {f.stem for f in labels_dir.glob('*.txt')}\n",
    "    \n",
    "    # 1. Im√°genes sin labels\n",
    "    missing_labels = image_stems - label_stems\n",
    "    if missing_labels:\n",
    "        issues.append(f\"‚ö†Ô∏è {len(missing_labels)} im√°genes sin archivo de label\")\n",
    "        for name in list(missing_labels)[:5]:\n",
    "            issues.append(f\"   - {name}\")\n",
    "        if len(missing_labels) > 5:\n",
    "            issues.append(f\"   ... y {len(missing_labels) - 5} m√°s\")\n",
    "    \n",
    "    # 2. Labels sin im√°genes\n",
    "    missing_images = label_stems - image_stems\n",
    "    if missing_images:\n",
    "        issues.append(f\"‚ö†Ô∏è {len(missing_images)} labels sin imagen correspondiente\")\n",
    "    \n",
    "    # 3. Verificar contenido de labels\n",
    "    invalid_bbox = 0\n",
    "    invalid_class = 0\n",
    "    empty_labels = 0\n",
    "    \n",
    "    for label_file in labels_dir.glob('*.txt'):\n",
    "        annotations = parse_yolo_label(label_file)\n",
    "        \n",
    "        if len(annotations) == 0:\n",
    "            empty_labels += 1\n",
    "            continue\n",
    "        \n",
    "        for ann in annotations:\n",
    "            # Verificar rango de coordenadas\n",
    "            if not (0 <= ann['x_center'] <= 1 and 0 <= ann['y_center'] <= 1):\n",
    "                invalid_bbox += 1\n",
    "            if not (0 < ann['width'] <= 1 and 0 < ann['height'] <= 1):\n",
    "                invalid_bbox += 1\n",
    "            \n",
    "            # Verificar clase v√°lida\n",
    "            if ann['class_id'] not in CLASS_NAMES:\n",
    "                invalid_class += 1\n",
    "    \n",
    "    if empty_labels > 0:\n",
    "        issues.append(f\"‚ÑπÔ∏è {empty_labels} im√°genes sin objetos (labels vac√≠os)\")\n",
    "    \n",
    "    if invalid_bbox > 0:\n",
    "        issues.append(f\"‚ùå {invalid_bbox} bounding boxes con coordenadas inv√°lidas\")\n",
    "    \n",
    "    if invalid_class > 0:\n",
    "        issues.append(f\"‚ùå {invalid_class} anotaciones con clase inv√°lida\")\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(f\"\\nüîç Verificaci√≥n de calidad - {split.upper()}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not issues:\n",
    "        print(\"‚úÖ No se encontraron problemas\")\n",
    "    else:\n",
    "        for issue in issues:\n",
    "            print(issue)\n",
    "    \n",
    "    print(f\"\\n   Total im√°genes: {len(image_stems)}\")\n",
    "    print(f\"   Total labels: {len(label_stems)}\")\n",
    "\n",
    "# Verificar cada split\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    check_data_quality(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumen y Recomendaciones\n",
    "\n",
    "Basado en el an√°lisis, aqu√≠ est√°n las recomendaciones para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Generar resumen y recomendaciones\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìã RESUMEN DEL DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(df_all) > 0:\n",
    "    print(f\"\\nüìä Estad√≠sticas generales:\")\n",
    "    print(f\"   - Total de anotaciones: {len(df_all)}\")\n",
    "    print(f\"   - Clases: {len(CLASS_NAMES)}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ Distribuci√≥n por split:\")\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        count = len(df_all[df_all['split'] == split])\n",
    "        print(f\"   - {split}: {count} anotaciones\")\n",
    "    \n",
    "    # Recomendaciones basadas en los datos\n",
    "    print(f\"\\nüí° RECOMENDACIONES:\")\n",
    "    \n",
    "    # 1. Tama√±o del dataset\n",
    "    train_count = len(df_train)\n",
    "    if train_count < 100:\n",
    "        print(f\"   ‚ö†Ô∏è Dataset peque√±o ({train_count} anotaciones). Considera:\")\n",
    "        print(f\"      - Usar augmentation agresivo\")\n",
    "        print(f\"      - Reducir √©pocas (50-100) para evitar overfitting\")\n",
    "        print(f\"      - Agregar m√°s datos si es posible\")\n",
    "    elif train_count < 500:\n",
    "        print(f\"   ‚ÑπÔ∏è Dataset moderado ({train_count} anotaciones).\")\n",
    "        print(f\"      - Augmentation est√°ndar deber√≠a funcionar bien\")\n",
    "        print(f\"      - 100-200 √©pocas recomendadas\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Dataset de buen tama√±o ({train_count} anotaciones).\")\n",
    "        print(f\"      - Puedes reducir augmentation si es necesario\")\n",
    "        print(f\"      - 100-300 √©pocas seg√∫n resultados\")\n",
    "    \n",
    "    # 2. Balance de clases\n",
    "    total = len(df_all)\n",
    "    percentages = {c: (len(df_all[df_all['class_id'] == c]) / total) * 100 for c in CLASS_NAMES.keys()}\n",
    "    max_pct = max(percentages.values())\n",
    "    min_pct = min(percentages.values())\n",
    "    \n",
    "    if max_pct / min_pct > 3:\n",
    "        print(f\"\\n   ‚ö†Ô∏è Clases desbalanceadas (ratio {max_pct/min_pct:.1f}:1)\")\n",
    "        print(f\"      - Considera usar class weights\")\n",
    "        print(f\"      - O agregar m√°s datos de la clase minoritaria\")\n",
    "    else:\n",
    "        print(f\"\\n   ‚úÖ Clases relativamente balanceadas\")\n",
    "    \n",
    "    # 3. Tama√±o de objetos\n",
    "    mean_area = (df_all['width'] * df_all['height']).mean()\n",
    "    if mean_area < 0.01:\n",
    "        print(f\"\\n   ‚ÑπÔ∏è Objetos peque√±os (√°rea promedio: {mean_area:.4f})\")\n",
    "        print(f\"      - Considera usar imgsz=1280 para mejor detecci√≥n\")\n",
    "        print(f\"      - Pero requiere m√°s VRAM\")\n",
    "    elif mean_area > 0.1:\n",
    "        print(f\"\\n   ‚úÖ Objetos de tama√±o mediano-grande (√°rea: {mean_area:.4f})\")\n",
    "        print(f\"      - imgsz=640 deber√≠a funcionar bien\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Listo para entrenar: python scripts/train.py\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No hay datos en el dataset\")\n",
    "    print(\"   Sigue las instrucciones en README.md para:\")\n",
    "    print(\"   1. Capturar screenshots VR\")\n",
    "    print(\"   2. Anotar con Roboflow\")\n",
    "    print(\"   3. Exportar en formato YOLOv8\")\n",
    "    print(\"   4. Colocar los archivos en data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pr√≥ximos Pasos\n",
    "\n",
    "1. Si el dataset se ve bien, procede al entrenamiento:\n",
    "   ```bash\n",
    "   python scripts/train.py\n",
    "   ```\n",
    "\n",
    "2. Si encontraste problemas, corr√≠gelos en Roboflow y re-exporta.\n",
    "\n",
    "3. Despu√©s del entrenamiento, documenta los resultados en `docs/benchmarks.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
